# 10-5. Statistical Inferences

The parameter β1β1, the slope of the population regression line, is of primary importance in regression analysis because it gives the true rate of change in the mean E\(y\)E\(y\) in response to a unit increase in the predictor variable _x_. For every unit increase in _x_ the mean of the response variable _y_ changes by β1β1 units, increasing if β1&gt;0β1&gt;0 and decreasing if β1&lt;0.β1&lt;0. We wish to construct confidence intervals for β1β1 and test hypotheses about it.

### Confidence Intervals for _β_1

The slope βˆ1β^1 of the least squares regression line is a point estimate of β1.β1. A confidence interval for β1β1 is given by the following formula.

#### 100\(1−α\)%100\(1−α\)% Confidence Interval for the Slope β1β1 of the Population Regression Line

βˆ1±tα∕2sεSSxx−−−−√β^1±tα∕2sεSSxx

where sε=SSEn−2−−−−√sε=SSEn−2 and the number of degrees of freedom is df=n−2.df=n−2.

The assumptions listed in [Section 10.3 "Modelling Linear Relationships with Randomness Present"](https://saylordotorg.github.io/text_introductory-statistics/s14-03-modelling-linear-relationships.html) must hold.

#### Definition

_The statistic_ sεsε _is called the_ sample standard deviation of errors_. It estimates the standard deviation_ _σ_ _of the errors in the population of_ _y-values for each fixed value of_ _x_ _\(see_ [_Figure 10.5 "The Simple Linear Model Concept"_](https://saylordotorg.github.io/text_introductory-statistics/s14-03-modelling-linear-relationships.html) _in_ [_Section 10.3 "Modelling Linear Relationships with Randomness Present"_](https://saylordotorg.github.io/text_introductory-statistics/s14-03-modelling-linear-relationships.html)_\)._

#### EXAMPLE 6

Construct the 95% confidence interval for the slope β1β1 of the population regression line based on the five-point sample data setxy20216283103x226810y01233

Solution:



#### EXAMPLE 7

Using the sample data in [Table 10.3 "Data on Age and Value of Used Automobiles of a Specific Make and Model"](https://saylordotorg.github.io/text_introductory-statistics/fwk-shafer-ch10_s04#fwk-shafer-ch10_s04_s02_t03) construct a 90% confidence interval for the slope β1β1 of the population regression line relating age and value of the automobiles of [Note 10.19 "Example 3"](https://saylordotorg.github.io/text_introductory-statistics/s14-04-the-least-squares-regression-l.html) in [Section 10.4 "The Least Squares Regression Line"](https://saylordotorg.github.io/text_introductory-statistics/s14-04-the-least-squares-regression-l.html). Interpret the result in the context of the problem.

Solution:



### Testing Hypotheses About _β_1

Hypotheses regarding β1β1 can be tested using the same five-step procedures, either the critical value approach or the _p_-value approach, that were introduced in [Section 8.1 "The Elements of Hypothesis Testing"](https://saylordotorg.github.io/text_introductory-statistics/fwk-shafer-ch08_s01#fwk-shafer-ch08_s01) and [Section 8.3 "The Observed Significance of a Test"](https://saylordotorg.github.io/text_introductory-statistics/fwk-shafer-ch08_s03#fwk-shafer-ch08_s03) of [Chapter 8 "Testing Hypotheses"](https://saylordotorg.github.io/text_introductory-statistics/s12-testing-hypotheses.html). The null hypothesis always has the form H0:β1=B0H0:β1=B0 where _B_0 is a number determined from the statement of the problem. The three forms of the alternative hypothesis, with the terminology for each case, are:

| Form of _Ha_ | Terminology |
| :--- | :--- |
| Ha:β1&lt;B0Ha:β1&lt;B0 | Left-tailed |
| Ha:β1&gt;B0Ha:β1&gt;B0 | Right-tailed |
| Ha:β1≠B0Ha:β1≠B0 | Two-tailed |

The value zero for _B_0 is of particular importance since in that case the null hypothesis is H0:β1=0H0:β1=0, which corresponds to the situation in which _x_ is not useful for predicting _y_. For if β1=0β1=0 then the population regression line is horizontal, so the mean E\(y\)E\(y\) is the same for every value of _x_ and we are just as well off in ignoring _x_ completely and approximating _y_ by its average value. Given two variables _x_ and _y_, the burden of proof is that _x_ is useful for predicting _y_, not that it is not. Thus the phrase “test whether _x_ is useful for prediction of _y_,” or words to that effect, means to perform the testH0:β1=0 vs. Ha:β1≠0H0:β1=0 vs. Ha:β1≠0

#### Standardized Test Statistic for Hypothesis Tests Concerning the Slope β1β1 of the Population Regression Line

T=βˆ1−B0sε/SSxx−−−−√T=β^1−B0sε∕SSxx

The test statistic has Student’s _t_-distribution with df=n−2df=n−2 degrees of freedom.

The assumptions listed in [Section 10.3 "Modelling Linear Relationships with Randomness Present"](https://saylordotorg.github.io/text_introductory-statistics/s14-03-modelling-linear-relationships.html) must hold.

#### EXAMPLE 8

Test, at the 2% level of significance, whether the variable _x_ is useful for predicting _y_ based on the information in the five-point data setxy20216283103x226810y01233

Solution:



#### EXAMPLE 9

A car salesman claims that automobiles between two and six years old of the make and model discussed in [Note 10.19 "Example 3"](https://saylordotorg.github.io/text_introductory-statistics/s14-04-the-least-squares-regression-l.html) in [Section 10.4 "The Least Squares Regression Line"](https://saylordotorg.github.io/text_introductory-statistics/s14-04-the-least-squares-regression-l.html) lose more than $1,100 in value each year. Test this claim at the 5% level of significance.

Solution:

