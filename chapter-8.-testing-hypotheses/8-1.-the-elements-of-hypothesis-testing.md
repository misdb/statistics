# 8-1. The Elements of Hypothesis Testing

{% file src="../.gitbook/assets/chapter-08-kor.pptx" caption="가설 검정" %}

{% file src="../.gitbook/assets/ch9\_hyp\_testing.pdf" caption="Testing of Hypothesis" %}

A manufacturer of emergency equipment asserts that a respirator that it makes delivers pure air for 75 minutes on average. A government regulatory agency is charged with testing such claims, in this case to verify that the average time is not less than 75 minutes. To do so it would select a random sample of respirators, compute the mean time that they deliver pure air, and compare that mean to the asserted time 75 minutes.

In the sampling that we have studied so far the goal has been to estimate a population parameter. But the sampling done by the government agency has a somewhat different objective, not so much to _estimate_ the population mean $$μ$$ as to _test_ an assertion—or a **hypothesis**—about it, namely, whether it is as large as 75 or not. The agency is not necessarily interested in the actual value of $$μ,$$ just whether it is as claimed. Their sampling is done to perform a test of hypotheses, the subject of this chapter.

### 8.1 The Elements of Hypothesis Testing

#### LEARNING OBJECTIVES

1. To understand the logical framework of tests of hypotheses.
2. To learn basic terminology connected with hypothesis testing.
3. To learn fundamental facts about hypothesis testing.

## 1. Types of Hypotheses

A _**hypothesis**_ about the value of a population parameter is an assertion about its value. As in the introductory example we will be concerned with testing the truth of two competing hypotheses, only one of which can be true.

> _The_ **null hypothesis**_, denoted_ $$H_0$$ _, is the statement about the population parameter that is assumed to be true unless there is convincing evidence to the contrary_.

> _The_ **alternative hypothesis**_, denoted_ $$H_a$$ _, is a statement about the population parameter that is contradictory to the null hypothesis, and is accepted as true only if there is convincing evidence in favor of it._

> **Hypothesis testing** _is a statistical procedure in which a choice is made between a null hypothesis and an alternative hypothesis based on information in a sample._

The **end result of a hypotheses testing procedure** is a choice of one of the following two possible conclusions:

1. Reject $$H_0$$ \(and therefore accept $$H_a$$ \), or
2. Fail to reject $$H_0$$ \(and therefore fail to accept $$H_a$$ \).

The null hypothesis typically represents the status quo, or what has historically been true. In the example of the respirators, we would believe the claim of the manufacturer unless there is reason not to do so, so the null hypotheses is $$H_0 : μ=75$$ . The alternative hypothesis in the example is the contradictory statement $$H_a:μ<75$$ . 

> The **null hypothesis** will always be an assertion _containing an equals sign,_ but depending on the situation the **alternative hypothesis** can have _any one of three forms_: _with the symbol “_ $$<$$ _,” as in the example just discussed, with the symbol “_ $$>$$ _,” or with the symbol “_ $$≠$$ _”_ .



The following two examples illustrate the latter two cases.

**EXAMPLE 1.** A publisher of college textbooks claims that the average price of all hardbound college textbooks is $127.50. A student group believes that the actual mean is higher and wishes to test their belief. State the relevant null and alternative hypotheses.

**\[ Solution \]**

* $$H_0:μ=127.50.$$ 
* $$H_a:μ>127.50.$$ 

The default option is to accept the publisher’s claim unless there is compelling evidence to the contrary. Thus the null hypothesis is $$H_0:μ=127.50.$$ Since the student group thinks that the average textbook price is _greater_ than the publisher’s figure, the alternative hypothesis in this situation is $$H_a:μ>127.50.$$   


**EXAMPLE 2.** The recipe for a bakery item is designed to result in a product that contains 8 grams of fat per serving. The quality control department samples the product periodically to insure that the production process is working as designed. State the relevant null and alternative hypotheses.

**\[ Solution \]**

* $$​H_0:μ=8.$$ 
* ​​ $$H_a:μ\ne8.$$ 

The default option is to assume that the product contains the amount of fat it was formulated to contain unless there is compelling evidence to the contrary. Thus the null hypothesis is $$H_0:μ=8.0.$$ Since to contain either more fat than desired or to contain less fat than desired are both an indication of a faulty production process, the alternative hypothesis in this situation is that the mean is _different_ from 8.0, so   
 $$H_a:μ≠8.0.$$ 



In "EXAMPLE 1", the textbook example, it might seem more natural that the publisher’s claim be that the average price is at most $127.50, not exactly $127.50. If the claim were made this way, then the null hypothesis would be $$H_0:μ≤127.50$$ , and the value $127.50 given in the example would be the one that is least favorable to the publisher’s claim, the null hypothesis. It is always true that if the null hypothesis is retained for its least favorable value, then it is retained for every other value.

Thus in order to make the null and alternative hypotheses easy for the student to distinguish, in every example and problem in this text we will always present one of the two competing claims about the value of a parameter with an equality. 

_The claim expressed with an equality is the **null hypothesis**._ This is the same as always stating the null hypothesis in the least favorable light. So in the introductory example about the respirators, we stated the manufacturer’s claim as “the average is 75 minutes” instead of the perhaps more natural “the average is at least 75 minutes,” essentially reducing the presentation of the null hypothesis to its worst case.

**The first step in hypothesis testing is to** _**identify the null and alternative hypotheses**_**.**

## 2. The Logic of Hypothesis Testing

Although we will study hypothesis testing in situations other than for a single population mean \(for example, for a population proportion instead of a mean or in comparing the means of two different populations\), in this section the discussion will always be given in terms of **a single population mean** $$μ$$ .

The **null hypothesis** always has the form $$H_0:μ=μ_0$$ for a specific number $$μ_0$$ \(in the respirator example $$μ_0=75$$ , in the textbook example $$μ_0 = 127.5$$ , and in the baked goods example $$μ_0 = 8.0$$ \). Since the null hypothesis is accepted unless there is strong evidence to the contrary, the test procedure is based on the **initial assumption that** $$μ_0$$ **is true**. This point is so important that we will repeat it in a display:

> _The test procedure is based on the initial assumption that_ $$μ_0$$ _is true._

The criterion for judging between $$H_0$$ and $$H_a$$ based on the sample data is: if the value of $$\bar{X}$$ would be highly unlikely to occur if $$H_0$$ were true, but favors the truth of $$H_a$$ , then we reject $$H_0$$ in favor of $$H_a$$ . Otherwise we do not reject $$H_0$$ .

Supposing for now that $$\bar{X}$$ follows a normal distribution, when the null hypothesis is true the density function for the sample mean $$\bar{X}$$ must be as in [Figure 8.1 "The Density Curve for "](https://saylordotorg.github.io/text_introductory-statistics/s12-testing-hypotheses.html#fwk-shafer-ch08_s01_s02_f01): a bell curve centered at $$μ_0$$. Thus if $$H_0$$ is true then $$\bar{X}$$- is likely to take a value near $$μ_0$$ and is unlikely to take values far away. Our decision procedure therefore reduces simply to:

1. if $$H_a$$ has the form $$H_a:μ<μ_0$$ then reject $$H_0$$ if $$\bar{x}$$ is far to the left of $$μ_0$$;
2. if $$H_a$$ has the form $$H_a:μ>μ_0$$ then reject $$H_0$$ if $$\bar{x}$$ is far to the right of $$μ_0$$;
3. if $$H_a$$ has the form $$H_a:μ \neμ_0$$ then reject $$H_0$$ if $$\bar{x}$$ is far away from $$μ_0$$ in either direction.

Figure 8.1 The Density Curve for $$\bar{X}$$ if $$H_0$$ Is True

![](https://saylordotorg.github.io/text_introductory-statistics/section_12/b91b73d0dbbd53dc069a390a463118a2.jpg)

Think of the respirator example, for which the null hypothesis is $$H_0:μ=75$$, the claim that the average time air is delivered for _all_ respirators is 75 minutes. If the sample mean is 75 or greater then we certainly would not reject $$H_0$$ \(since there is no issue with an emergency respirator delivering air even longer than claimed\).

If the sample mean is slightly less than 75 then we would logically attribute the difference to sampling error and also not reject $$H_0$$ either.

Values of the sample mean that are smaller and smaller are less and less likely to come from a population for which the population mean is 75. Thus if the sample mean is far less than 75, say around 60 minutes or less, then we would certainly reject $$H_0$$, because we know that it is highly unlikely that the average of a sample would be so low if the population mean were 75. This is the _**rare event criterion**_ for rejection: what we actually observed \( $$\bar{X}<60$$ \) would be so rare an event if $$μ = 75$$ were true that we regard it as much more likely that the alternative hypothesis $$μ <75$$ holds.

In summary, to decide between $$H_0$$ and $$H_a$$in this example we would select a “**rejection region**” of values sufficiently far to the left of 75, based on the rare event criterion, and reject $$H_0$$ if the sample mean $$\bar{X}$$ lies in the rejection region, but not reject $$H_0$$ if it does not.

## 3. The Rejection Region

Each different form of the **alternative hypothesis** $$H_a$$ has its **own kind of rejection region**:

1. if \(as in the respirator example\) $$H_a$$ has the form $$H_a:μ<μ_0$$ , we reject $$H_0$$ if $$\bar{X}$$ is far to the left of $$μ_0$$, that is, to the left of some number $$C$$ , so the rejection region has the form of an interval $$(−∞,C]$$ ;
2. if \(as in the textbook example\) $$H_a$$ has the form $$H_a:μ>μ_0$$, we reject $$H_0$$ if $$\bar{X}$$ is far to the right of $$μ_0$$, that is, to the right of some number $$C$$, so the rejection region has the form of an interval $$[C,∞)$$ ;
3. if \(as in the baked good example\) $$H_a$$ has the form $$H_a:μ \neμ_0$$ , we reject $$H_0$$ if $$\bar{X}$$ is far away from $$μ_0$$ in either direction, that is, either to the left of some number $$C$$ or to the right of some other number $$C'$$, so the rejection region has the form of the union of two intervals $$ (−∞,C]∪[C′,∞)$$ .

The key issue in our line of reasoning is the question of how to determine the number $$C$$ or numbers $$C$$ and $$C'$$, called the _**critical value**_ **or** _**critical values**_ of the statistic, that determine the rejection region.

> _The_ **critical value** _or_ **critical values** _of a test of hypotheses are the number or numbers that determine the rejection region._

**Suppose the rejection region is a single interval**, so we need to select a single number $$C$$. Here is the procedure for doing so. We select a small probability, denoted $$α$$ , say 1%, which we take as our definition of “rare event:” an event is “rare” if its probability of occurrence is less than $$α$$. \(In all the examples and problems in this text the value of $$α$$ will be given already.\) 

The probability that $$\bar{X}$$ takes a value in **an interval** is the area under its density curve and above that interval, so as shown in [Figure 8.2](https://saylordotorg.github.io/text_introductory-statistics/s12-testing-hypotheses.html#fwk-shafer-ch08_s01_s03_f01) \(drawn under the assumption that _H_0 is true, so that the curve centers at $$μ_0$$\) the critical value $$C$$ is the value of $$\bar{X}$$ that cuts off a tail area $$α$$ in the probability density curve of $$\bar{X}$$. 

When the rejection region is in **two pieces**, that is, composed of **two intervals**, the total area above both of them must be $$α$$, so the area above each one is $$α/2$$, as also shown in [Figure 8.2](https://saylordotorg.github.io/text_introductory-statistics/s12-testing-hypotheses.html#fwk-shafer-ch08_s01_s03_f01).

**Figure 8.2**

![Three Kinds of Rejection Region](https://saylordotorg.github.io/text_introductory-statistics/section_12/72f0cd42fda04cdfb0341bcfe11601c1.jpg)

**The number** $$α$$ **is the total area of a tail or a pair of tails.**



**EXAMPLE 3.** In the context of "EXAMPLE 2", suppose that it is known that the population is normally distributed with standard deviation $$σ = 0.15$$ gram, and suppose that the test of hypotheses $$H_0:μ=8.0$$ versus $$H_a:μ≠8.0$$ will be performed with a sample of size 5. Construct the rejection region for the test for the choice $$α=0.10$$ . Explain the decision procedure and interpret it.

**\[ Solution \]**

* $$μ_\bar{X}=μ=8.0$$ ,  $$σ_\bar{X}=(σ∕\sqrt{n}) =(0.15/ \sqrt{5}) = 0.067.$$ 
* $$α=0.10$$,   $$(α∕2)=(0.10∕2)=0.05$$, $$z_{0.05}=1.645$$ 
* so _C_ and _C_′ are 1.645 standard deviations of $$\bar{X}$$ to the right and left of its mean 8.0  $$C = \mu_0 - z_{\alpha/2}\sigma_\bar{X} = 8.0 − (1.645)(0.067) = 7.89 $$   $$C' = \mu_0 + z_{\alpha/2}\sigma_\bar{X} =8.0 + (1.645)(0.067) = 8.11$$ 

![Rejection Region for the Choice &#x3B1;=0.10 ](https://saylordotorg.github.io/text_introductory-statistics/section_12/6ed58a35480090fa999b53b443a266a5.jpg)

{% tabs %}
{% tab title="R Source" %}
```text
n <- 5
mu <- 8
sd <- 0.15
alpha <- 0.10

se <- sd / sqrt(n)

# in case of two-tail test
z <- qnorm(1-alpha/2); z

lc <- mu - z * se
uc <- mu + z * se

lc   # lower critical value
uc   # upper critical value
```
{% endtab %}

{% tab title="Result" %}
```text
> z <- qnorm(1-alpha/2); z
## [1] 1.644854
> 
> lc <- mu - z * se
> uc <- mu + z * se
> 
> lc   # lower critical value
## [1] 7.88966
> uc   # upper critical value
## [1] 8.11034
```
{% endtab %}
{% endtabs %}



Because the rejection regions are computed based on areas in tails of distributions, as shown in Figure 8.2, hypothesis tests are classified according to the form of the alternative hypothesis in the following way.

> _If_  $$H_a$$ _has the form_  $$H_a:μ \neμ_0$$  _the test is called a_ **two-tailed test**_._
>
> _If_  $$H_a$$ _has the form_  $$H_a:μ <  μ_0$$  _the test is called a_ **left-tailed test**_._
>
> _If_  $$H_a$$ _has the form_  $$H_a:μ >  μ_0$$  _the test is called a_ **right-tailed test**_._
>
> _Each of the last two forms is also called a_ **one-tailed test**_._

## 4. Two Types of Errors

The format of the testing procedure in general terms is to take a sample and use the information it contains to come to a decision about the two hypotheses. As stated before our decision will always be either

1. reject the null hypothesis $$H_o$$ in favor of the alternative $$H_a$$ presented, or
2. do not reject the null hypothesis  $$H_0$$ in favor of the alternative  $$H_a$$ presented.

There are **four possible outcomes of hypothesis testing procedure**, as shown in the following table:

|  |  | **True State of Nature** |  |
| :--- | :--- | :--- | :--- |
|  |  | $$Ho$$ ia true | $$Ho$$ is false |
| **Our Decision** | Do not reject $$Ho$$  | Correct decision | **Type II error \(** $$\beta$$ **\)** |
|  | Reject $$Ho$$  | **Type I error \(** $$\alpha$$ **\)** | Correct Decision |

As the table shows, there are two ways to be right and two ways to be wrong. Typically to reject $$H_0$$ when it is actually true is a more serious error than to fail to reject it when it is false, so the former error is labeled “Type I” and the latter error “Type II.”

#### 

> _In a test of hypotheses, a_ **Type I error** _is the decision to reject_ $$H_0$$ _when it is in fact true. A_ **Type II error** _is the decision not to reject_  $$H_0$$  _when it is in fact not true._

Unless we perform a census we do not have certain knowledge, so we do not know whether our decision matches the true state of nature or if we have made an error. We reject $$H_0$$ if what we observe would be a “rare” event if $$H_0$$ were true. But rare events are not impossible: they occur with probability $$α$$. Thus when $$H_0$$ is true, a rare event will be observed in the proportion $$α$$ of repeated similar tests, and $$H_0$$ will be erroneously rejected in those tests. Thus $$α$$ is the probability that in following the testing procedure to decide between $$H_0$$ and $$H_a$$ we will make a **Type I error**.

#### 

> _The number_ $$α$$ _that is used to determine the rejection region is called the_ **level of significance of the test**_. It is the probability that the test procedure will result in a Type I error._

The probability of making a **Type II error** is too complicated to discuss in a beginning text, so we will say no more about it than this: for a fixed sample size, choosing $$α$$ smaller in order to reduce the chance of making a Type I error has the effect of increasing the chance of making a Type II error. 

**The only way to simultaneously reduce the chances of making either kind of error is to increase the sample size.**

## 5. Standardizing the Test Statistic

Hypotheses testing will be considered in a number of contexts, and great unification as well as simplification results when the relevant sample statistic is _standardized_ by subtracting its mean from it and then dividing by its standard deviation. The resulting statistic is called a _**standardized test statistic**_. In every situation treated in this and the following two chapters the standardized test statistic will have either the standard normal distribution or Student’s _t_-distribution.

> _A_ **standardized test statistic** _for a hypothesis test is the statistic that is formed by subtracting from the statistic of interest its mean and dividing by its standard deviation._

For example, reviewing [Note 8.14 "Example 3"](https://saylordotorg.github.io/text_introductory-statistics/s12-testing-hypotheses.html#fwk-shafer-ch08_s01_s03_n02), if instead of working with the sample mean $$\bar{X}$$ we instead work with the test statistic $$\frac{\bar{X}−8.0} {0.067} .$$ 

then the distribution involved is standard normal and the critical values are just $$±z_{0.05}$$ . The extra work that was done to find that $$C = 7.89$$ and $$C′=8.11$$ is eliminated. 

In every hypothesis test in this book the standardized test statistic will be governed by either the **standard normal distribution** or **Student’s** _**t**_**-distribution**. Information about rejection regions is summarized in the following tables:

| When the test statistic has  **the standard normal distribution:** |  |  |
| :--- | :--- | :--- |
| Symbol in _Ha_ | Terminology | Rejection Region |
| $$<$$  | Left-tailed test | $$(−∞,−z_α]$$  |
| $$>$$  | Right-tailed test | $$[z_α,∞)$$  |
| $$≠$$  | Two-tailed test | $$(−∞,−z_{α∕2}]∪[z_{α∕2},∞)$$  |

| When the test statistic has  **Student’s** _**t**_**-distribution:** |  |  |
| :--- | :--- | :--- |
| Symbol in _Ha_ | Terminology | Rejection Region |
| $$<$$  | Left-tailed test | $$(−∞,−t_α]$$ |
| $$>$$  | Right-tailed test | $$[t_α,∞)$$ |
| $$≠$$  | Two-tailed test | $$(−∞,−t_{α∕2}]∪[t_{α∕2},∞)$$ |



Every instance of hypothesis testing discussed in this and the following two chapters will have a rejection region like one of the six forms tabulated in the tables above.

No matter what the context a test of hypotheses can always be performed by applying the following systematic procedure, which will be illustrated in the examples in the succeeding sections.

> **Systematic Hypothesis Testing Procedure: Critical Value Approach**
>
> 1. Identify the null and alternative hypotheses. 
> 2. Identify the relevant test statistic and its distribution.
> 3. Compute from the data the value of the test statistic.
> 4. Construct the rejection region.
> 5. Compare the value computed in Step 3 to the rejection region constructed in Step 4 and make a decision. Formulate the decision in the context of the problem, if applicable.

The procedure that we have outlined in this section is called the “**Critical Value Approach**” to hypothesis testing to distinguish it from an alternative but equivalent approach that will be introduced at the end of [Section 8.3 "The Observed Significance of a Test"](https://saylordotorg.github.io/text_introductory-statistics/fwk-shafer-ch08_s03#fwk-shafer-ch08_s03).

