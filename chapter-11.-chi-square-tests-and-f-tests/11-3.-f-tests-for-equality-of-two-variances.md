# 11-3. F-tests for Equality of Two Variances

### _F_-Distributions

Another important and useful family of distributions in statistics is the family of _F_-distributions. Each member of the _F_-distribution family is specified by a pair of parameters called _degrees of freedom_ and denoted df1df1 and df2.df2. [Figure 11.7 "Many "](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html#fwk-shafer-ch11_s03_s01_f01) shows several _F_-distributions for different pairs of degrees of freedom. An FF random variable is a random variable that assumes only positive values and follows an _F_-distribution.

Figure 11.7 Many _F_-Distributions![](https://saylordotorg.github.io/text_introductory-statistics/section_15/75fd6a2d869b9403de8408b42a054db9.jpg)

The parameter df1df1 is often referred to as the _numerator_ degrees of freedom and the parameter df2df2 as the _denominator_ degrees of freedom. It is important to keep in mind that they are not interchangeable. For example, the _F_-distribution with degrees of freedom df1=3df1=3 and df2=8df2=8 is a different distribution from the _F_-distribution with degrees of freedom df1=8df1=8 and df2=3.df2=3.

#### Definition

_The value of the_ _F random variable_ _F_ _with degrees of freedom_ df1df1 _and_ df2df2 _that cuts off a right tail of area_ _c_ _is denoted_ _Fc_ _and is called a_ **critical value**. _See_ [_Figure 11.8_](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html#fwk-shafer-ch11_s03_s01_f02)_._

Figure 11.8_Fc_ Illustrated![](https://saylordotorg.github.io/text_introductory-statistics/section_15/59a41857cbaae56b820472577df06b26.jpg)

Tables containing the values of _Fc_ are given in [Chapter 11 "Chi-Square Tests and "](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html). Each of the tables is for a fixed collection of values of _c_, either 0.900, 0.950, 0.975, 0.990, and 0.995 \(yielding what are called “lower” critical values\), or 0.005, 0.010, 0.025, 0.050, and 0.100 \(yielding what are called “upper” critical values\). In each table critical values are given for various pairs \(df1,df2\).\(df1,df2\). We illustrate the use of the tables with several examples.

#### EXAMPLE 3

Suppose _F_ is an _F_ random variable with degrees of freedom df1=5df1=5 and df2=4.df2=4. Use the tables to find

1. _F_0.10
2. _F_0.95

Solution:





#### EXAMPLE 4

Suppose FF is an _F_ random variable with degrees of freedom df1=2df1=2 and df2=20.df2=20. Let α=0.05.α=0.05. Use the tables to find

1. FαFα
2. Fα∕2Fα∕2
3. F1−αF1−α
4. F1−α∕2F1−α∕2

Solution:



A fact that sometimes allows us to find a critical value from a table that we could not read otherwise is:

If Fu\(r,s\)Fu\(r,s\) denotes the value of the _F_-distribution with degrees of freedom df1=rdf1=r and df2=sdf2=s that cuts off a right tail of area _u_, thenFc\(k,ℓ\)=1F1−c\(ℓ,k\)Fc\(k,ℓ\)=1F1−c\(ℓ,k\)

#### EXAMPLE 5

Use the tables to find

1. _F_0.01 for an _F_ random variable with df1=13df1=13 and df2=8df2=8
2. _F_0.975 for an _F_ random variable with df1=40df1=40 and df2=10df2=10

Solution:



### _F_-Tests for Equality of Two Variances

In [Chapter 9 "Two-Sample Problems"](https://saylordotorg.github.io/text_introductory-statistics/s13-two-sample-problems.html) we saw how to test hypotheses about the difference between two population means μ1μ1 and μ2.μ2. In some practical situations the difference between the population standard deviations σ1σ1 and σ2σ2 is also of interest. Standard deviation measures the variability of a random variable. For example, if the random variable measures the size of a machined part in a manufacturing process, the size of standard deviation is one indicator of product quality. A smaller standard deviation among items produced in the manufacturing process is desirable since it indicates consistency in product quality.

For theoretical reasons it is easier to compare the squares of the population standard deviations, the population variances σ21σ12 and σ22.σ22. This is not a problem, since σ1=σ2σ1=σ2 precisely when σ21=σ22σ12=σ22, σ1&lt;σ2σ1&lt;σ2 precisely when σ21&lt;σ22σ12&lt;σ22, and σ1&gt;σ2σ1&gt;σ2 precisely when σ21&gt;σ22.σ12&gt;σ22.

The null hypothesis always has the form H0:σ21=σ22.H0:σ12=σ22. The three forms of the alternative hypothesis, with the terminology for each case, are:

| Form of _Ha_ | Terminology |
| :--- | :--- |
| Ha:σ21&gt;σ22Ha:σ12&gt;σ22 | Right-tailed |
| Ha:σ21&lt;σ22Ha:σ12&lt;σ22 | Left-tailed |
| Ha:σ21≠σ22Ha:σ12≠σ22 | Two-tailed |

Just as when we test hypotheses concerning two population means, we take a random sample from each population, of sizes _n_1 and _n_2, and compute the sample standard deviations _s_1 and _s_2. In this context the samples are always independent. The populations themselves must be normally distributed.

#### Test Statistic for Hypothesis Tests Concerning the Difference Between Two Population Variances

F=s21s22F=s12s22

If the two populations are normally distributed and if H0:σ21=σ22H0:σ12=σ22 is true then under independent sampling _F_ approximately follows an _F_-distribution with degrees of freedom df1=n1−1df1=n1−1 and df2=n2−1.df2=n2−1.

A test based on the test statistic FF is called an _F_-test.

A most important point is that while the rejection region for a right-tailed test is exactly as in every other situation that we have encountered, because of the asymmetry in the _F_-distribution the critical value for a left-tailed test and the lower critical value for a two-tailed test have the special forms shown in the following table:

| Terminology | Alternative Hypothesis | Rejection Region |
| :--- | :--- | :--- |
| Right-tailed | Ha:σ21&gt;σ22Ha:σ12&gt;σ22 | F≥FαF≥Fα |
| Left-tailed | Ha:σ21&lt;σ22Ha:σ12&lt;σ22 | F≤F1−αF≤F1−α |
| Two-tailed | Ha:σ21≠σ22Ha:σ12≠σ22 | F≤F1−α∕2F≤F1−α∕2 or F≥Fα∕2F≥Fα∕2 |

[Figure 11.9 "Rejection Regions: \(a\) Right-Tailed; \(b\) Left-Tailed; \(c\) Two-Tailed"](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html#fwk-shafer-ch11_s03_s02_f01) illustrates these rejection regions.

Figure 11.9 Rejection Regions: \(a\) Right-Tailed; \(b\) Left-Tailed; \(c\) Two-Tailed![](https://saylordotorg.github.io/text_introductory-statistics/section_15/da58e4f2977f4b9644c6f0c320af4429.jpg)

The test is performed using the usual five-step procedure described at the end of [Section 8.1 "The Elements of Hypothesis Testing"](https://saylordotorg.github.io/text_introductory-statistics/fwk-shafer-ch08_s01#fwk-shafer-ch08_s01) in [Chapter 8 "Testing Hypotheses"](https://saylordotorg.github.io/text_introductory-statistics/s12-testing-hypotheses.html).

#### EXAMPLE 6

One of the quality measures of blood glucose meter strips is the consistency of the test results on the same sample of blood. The consistency is measured by the variance of the readings in repeated testing. Suppose two types of strips, _A_ and _B_, are compared for their respective consistencies. We arbitrarily label the population of Type _A_ strips Population 1 and the population of Type _B_ strips Population 2. Suppose 15 Type _A_ strips were tested with blood drops from a well-shaken vial and 20 Type _B_ strips were tested with the blood from the same vial. The results are summarized in [Table 11.16 "Two Types of Test Strips"](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html#fwk-shafer-ch11_s03_s02_t01). Assume the glucose readings using Type _A_ strips follow a normal distribution with variance σ21σ12 and those using Type _B_ strips follow a normal distribution with variance with σ22.σ22. Test, at the 10% level of significance, whether the data provide sufficient evidence to conclude that the consistencies of the two types of strips are different.

TABLE 11.16 TWO TYPES OF TEST STRIPS

| Strip Type | Sample Size | Sample Variance |
| :--- | :--- | :--- |
| _A_ | n1=16n1=16 | s21=2.09s12=2.09 |
| _B_ | n2=21n2=21 | s22=1.10s22=1.10 |

Solution:







#### EXAMPLE 7

In the context of [Note 11.27 "Example 6"](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html#fwk-shafer-ch11_s03_s02_n02), suppose Type _A_ test strips are the current market leader and Type _B_ test strips are a newly improved version of Type _A_. Test, at the 10% level of significance, whether the data given in [Table 11.16 "Two Types of Test Strips"](https://saylordotorg.github.io/text_introductory-statistics/s15-chi-square-tests-and-f-tests.html#fwk-shafer-ch11_s03_s02_t01) provide sufficient evidence to conclude that Type _B_ test strips have better consistency \(lower variance\) than Type _A_ test strips.

Solution:







