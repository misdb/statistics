# 4-4. Binomial Distribution

The experiment of tossing a fair coin three times and the experiment of observing the genders according to birth order of the children in a randomly selected three-child family are completely different, but the random variables that count the number of heads in the coin toss and the number of boys in the family \(assuming the two genders are equally likely\) are the same random variable, the one with probability distribution

| x | 0 | 1 | 2 | 3 |
| :--- | :--- | :--- | :--- | :--- |
| P\(x\) | 0.125 | 0.375 | 0.375 | 0.125 |

A histogram that graphically illustrates this probability distribution is given in [Figure 4.4 "Probability Distribution for Three Coins and Three Children"](https://saylordotorg.github.io/text_introductory-statistics/s08-03-the-binomial-distribution.html#fwk-shafer-ch04_s03_f01). What is common to the two experiments is that we perform three identical and independent trials of the same action, each trial has only two outcomes \(heads or tails, boy or girl\), and the probability of success is the same number, 0.5, on every trial. 

The random variable that is generated is called the _binomial random variable_ **with parameters** $$n = 3$$ **and** $$p = 0.5$$ . This is just one case of a general situation.

Figure 4.4 Probability Distribution for Three Coins and Three Children

![](https://saylordotorg.github.io/text_introductory-statistics/section_08/38928bb96eec1a3decfd6ac8e189a437.jpg)



> _Suppose a random experiment has the following characteristics._
>
> 1. _There are_ $$n$$ ****_**identical and independent trials** of a common procedure._
> 2. _There are **exactly two possible outcomes for each trial,** one termed “**success**” and the other “**failure.**”_
> 3. _The **probability of success** on any one trial is the same number_ $$p$$ .
>
> _Then the discrete random variable_ $$X$$ _that counts the number of successes in the_ $$n$$ _trials is the_ **binomial random variable with parameters** $$n$$ **and** $$p$$ _. We also say that_ $$X$$ **has a binomial distribution** **with parameters** _n_ **and** _p_.



The following **four examples** illustrate the definition. Note how in every case “success” is the outcome that is counted, not the outcome that we prefer or think is better in some sense.

1. A random sample of 125 students is selected from a large college in which the proportion of students who are females is 57%. Suppose $$X$$ denotes the number of female students in the sample. In this situation there are $$n = 125$$ identical and independent trials of a common procedure, selecting a student at random; there are exactly two possible outcomes for each trial, “success” \(what we are counting, that the student be female\) and “failure;” and finally the probability of success on any one trial is the same number $$p = 0.57$$ . $$X$$ is a binomial random variable with parameters $$n = 125$$ and $$p = 0.57$$.
2. A multiple-choice test has 15 questions, each of which has five choices. An unprepared student taking the test answers each of the questions completely randomly by choosing an arbitrary answer from the five provided. Suppose $$X$$ denotes the number of answers that the student gets right. $$X$$ is a binomial random variable with parameters $$n = 15$$ and $$p=1∕5=0.20$$ .
3. In a survey of 1,000 registered voters each voter is asked if he intends to vote for a candidate Titania Queen in the upcoming election. Suppose $$X$$ denotes the number of voters in the survey who intend to vote for Titania Queen. $$X$$ is a binomial random variable with $$n = 1000$$ and $$p$$ equal to the true proportion of voters \(surveyed or not\) who intend to vote for Titania Queen.
4. An experimental medication was given to 30 patients with a certain medical condition. Suppose $$X$$  denotes the number of patients who develop severe side effects. $$X$$ is a binomial random variable with $$n = 30$$ and $$p$$ equal to the true probability that a patient with the underlying condition will experience severe side effects if given that medication.



## 1. Bernoulli Distribution

성공확률이 일정한 1회의 시행에서 나오는 성공횟수의 확률분포를 말한다. 

> **Bernoulli Distribution**
>
> $$f(x) = p^x(1-p)^{(1-x)}, $$     $$x = 0, 1$$ 
>
> $$f(x) = \left\{\begin{matrix} p, & if \space x=1;\\  1-p, & if \space x=0 \end{matrix}\right.$$

> Expected Value and Variance of Bernoulli Distribution
>
> $$E(X) = \Sigma xf(x)= 0 \times(1-p) + 1 \times p = p$$ 
>
> $$Var(X) = E(X^2) - E(X)^2 = p-p^2 = p(1-p)$$



## 2. Probability Formula for a Binomial Random Variable



> If $$X$$ is a binomial random variable with parameters $$n $$ and $$p$$ ,  then
>
>                                       $$P(x=n) = \frac {n!} {x! (n−x)!} p^x q^{(n−x)}$$ 
>
> where $$q=(1−p)$$ and where for any counting number $$m$$ ,    
> $$m!$$ \(read “_m_ factorial”\) is defined by $$0!=1, 1!=1, 2!=1⋅2, 3!=1⋅2⋅3$$ 
>
> and in general          $$m!=1⋅2 ⋅ ⋅ ⋅ (m−1)⋅m$$



**EXAMPLE 8**. Seventeen percent of victims of financial fraud know the perpetrator of the fraud personally.

1. Use the formula to construct the probability distribution for the number $$X$$ of people in a random sample of five victims of financial fraud who knew the perpetrator personally.
2. A investigator examines five cases of financial fraud every day. Find the most frequent number of cases each day in which the victim knew the perpetrator.
3. A investigator examines five cases of financial fraud every day. Find the average number of cases per day in which the victim knew the perpetrator.

**\[ Solution \]** 

1. The random variable $$X$$ is binomial with parameters $$n = 5$$ and $$p = 0.17$$ ; $$q=1−p=0.83.$$ The possible values of $$X$$ are 0, 1, 2, 3, 4, and 5.  
  
    $$P(0)= \frac{5!}{0!5!} (0.17)^0 (0.83)^5  $$   
               $$=\frac{1⋅2⋅3⋅4⋅5}{(1)⋅(1⋅2⋅3⋅4⋅5)} 1⋅(0.3939040643)$$   
               $$=0.3939040643≈0.3939$$   
   $$P(1)= \frac{5!}{1!4!} (0.17)^1 (0.83)^4  $$

               $$=\frac{1⋅2⋅3⋅4⋅5}{(1)⋅(1⋅2⋅3⋅4)} (0.17)⋅(0.47458321)$$ 

               $$=0.4033957285≈0.4034$$ 

   $$P(2)= \frac{5!}{2!3!} (0.17)^2 (0.83)^3$$

               $$=\frac{1⋅2⋅3⋅4⋅5}{(1,2)⋅(1⋅2⋅3)} (0.289)⋅(0.571787)$$ 

               $$=0.165246443≈0.1652$$ 

  
   The remaining three probabilities are computed similarly, to give the probability distribution  
  
   x                 0                1              2              3               4               5  
   P\(x\)  0.3939     0.4034    0.1652    0.0338     0.0035     0.0001  
  
   The probabilities do not add up to exactly 1 because of rounding.  
   This probability distribution is represented by the histogram in [Figure 4.5 "Probability Distribution of the Binomial Random Variable in "](https://saylordotorg.github.io/text_introductory-statistics/s08-03-the-binomial-distribution.html#fwk-shafer-ch04_s03_s01_f01), which graphically illustrates just how improbable the events $$X=4$$ and $$X=5$$ are. The corresponding bar in the histogram above the number 4 is barely visible, if visible at all, and the bar above 5 is far too short to be visible.  
  
   Figure 4.5 Probability Distribution of the Binomial Random Variable in [Note 4.29 "Example 7"](https://saylordotorg.github.io/text_introductory-statistics/s08-03-the-binomial-distribution.html#fwk-shafer-ch04_s03_s01_n02)

![](https://saylordotorg.github.io/text_introductory-statistics/section_08/2fcd12630df97eb0e8aebc3dfb3e7887.jpg)

1. 2. The value of $$X$$ that is most likely is $$X=1$$, so the most frequent number of cases seen each day in which the victim knew the perpetrator is one. 
3. The average number of cases per day in which the victim knew the perpetrator is the mean of $$X$$, which is   $$μ=Σx P(x) = 0⋅0.3939+1⋅0.4034+2⋅0.1652+3⋅0.0338$$                                    $$+ 4⋅0.0035+5⋅0.0001 = 0.8497$$ 

{% tabs %}
{% tab title="R Source" %}
```text
library(Rstat)

# 1. Probability Distribution
n <- 5
p <- 0.17
x <- 0:5

px <- dbinom(x, n, p); px

# 2. E(X) and Var(X)
disc.exp(x, px)

# 3. Plot
disc.exp(x, px, prt=FALSE, plot=TRUE)
```
{% endtab %}

{% tab title="Probability Distribution Plot" %}
![](../.gitbook/assets/image%20%2823%29.png)

* The value of $$X$$ that is most likely is $$X=1$$.
{% endtab %}

{% tab title="E\(X\) and Var\(X\)" %}
```text
> disc.exp(x, px)
## E(X) = 0.85 
## V(X) = 1.428 - 0.85² = 0.706 
## D(X) = √(0.706) = 0.84 
```
{% endtab %}
{% endtabs %}

## **2.** Special Formulas for the Mean and Standard Deviation of a Binomial Random Variable



> If $$X$$ is a binomial random variable with parameters $$n$$ and $$p$$ , then
>
>     $$E(X) = \Sigma E(X_i) = \Sigma p=np$$         \($$X_i : $$ i-th Bernoulli random variable \)
>
>     $$Var(X) = \Sigma Var(X_i) = \Sigma p(1-p) =np(1-p)$$

> ==&gt;   $$μ=np$$ ,  $$σ^2=npq$$,    $$σ= \sqrt {npq}$$  
>
> where $$q=1-p$$ .

\*\*\*\*

**EXAMPLE 9.** Find the mean and standard deviation of the random variable $$X$$ of  "**Example 7**".

**\[ Solution \]**

The random variable _X_ is binomial with parameters $$n = 5$$ and $$p = 0.17$$ , and $$q=1−p=0.83$$ . Thus its mean and standard deviation are

$$μ=np=5⋅0.17=0.85  (exactly)$$ 

and

$$σ=\sqrt{npq}=\sqrt{5⋅0.17⋅0.83}=\sqrt{.7055}≈0.8399$$   


## 3. The Cumulative Probability Distribution of a Binomial Random Variable

In the place of the probability $$P(x)$$ the table contains the probability        

                         $$P(X≤x)=P(0)+P(1)+ ⋅ ⋅ ⋅ +P(x)$$ 

This is illustrated in the followinng Figure "**Cumulative Probabilities**". 

![Cumulative Probabilities](../.gitbook/assets/image%20%28217%29.png)



> If $$X$$ is a discrete random variable, then
>
>                       $$P(X≥x)=1−P(X≤x−1)$$   
>
>           and  $$P(x)=P(X≤x)−P(X≤x−1)$$



**EXAMPLE 10.** A student takes a ten-question true/false exam.

1. Find the probability that the student gets exactly six of the questions right simply by guessing the answer on every question.
2. Find the probability that the student will obtain a passing grade of 60% or greater simply by guessing.

**\[ Solution \]**

1. The probability sought is $$P(6)$$ . The formula gives  
    $$P(6)=\frac{10!}{(6!)(4!)}(.5)^6(.5)^4=0.205078125$$   


   Using the table,  
    $$P(6)=P(X≤6)−P(X≤5)=0.8281−0.6230=0.2051$$   

2. The student must guess correctly on at least 60% of the questions, which is $$(0.60)⋅10=6$$ questions. The probability sought is _not_ $$P(6)$$ \(an easy mistake to make\), but  
    $$P(X≥6)=P(6)+P(7)+P(8)+P(9)+P(10)$$ 

  
   Instead of computing each of these five numbers using the formula and adding them we can use the table to obtain  
    $$P(X≥6)=1−P(X≤5)=1−0.6230=0.3770$$   
  
   which is much less work and of sufficient accuracy for the situation at hand.

{% tabs %}
{% tab title="R Source" %}
```text
library(Rstat)

# 1. Probability Distribution
n <- 10
p <- 0.5
x <- 0:n

px <- dbinom(x, n, p); px

# 2. E(X) and Var(X)
disc.exp(x, px)

# 3. Plot
disc.exp(x, px, prt=FALSE, plot=TRUE)

# 4. Cumulative Distribution
disc.cdf(x, px)
```
{% endtab %}

{% tab title="Probability Distribution Plot" %}
![](../.gitbook/assets/image%20%2826%29.png)

* $$P(X=6)=0.205$$
{% endtab %}

{% tab title="Cumulative Distribution Plot" %}
![](../.gitbook/assets/image%20%28107%29.png)

* $$P(X≥6)=1−P(X≤5)=1−0.6230=0.3770$$
{% endtab %}
{% endtabs %}



**EXAMPLE 11.**  An appliance repairman services five washing machines on site each day. One-third of the service calls require installation of a particular part.

1. The repairman has only one such part on his truck today. Find the probability that the one part will be enough today, that is, that at most one washing machine he services will require installation of this particular part.
2. Find the minimum number of such parts he should take with him each day in order that the probability that he have enough for the day's service calls is at least 95%.

**\[ Solution \]**

Let $$X$$denote the number of service calls today on which the part is required. Then $$X$$ is a binomial random variable with parameters $$n = 5$$ and $$p=1/3=0.333$$ .

1. Note that the probability in question is not $$P(1)$$ , but rather $$P(X ≤ 1)$$ . Using the cumulative distribution table in [Chapter 12 "Appendix"](https://saylordotorg.github.io/text_introductory-statistics/s16-appendix.html),  $$P(X≤1)=0.4609$$  
2. The answer is the smallest number _x_ such that the table entry $$P(X≤x)$$ is at least 0.9500. Since $$P(X≤2)=0.7901$$ is less than 0.95, two parts are not enough. Since $$P(X≤3)=0.9547$$ is as large as 0.95, three parts will suffice at least 95% of the time. Thus the minimum needed is three.

{% tabs %}
{% tab title="R Source" %}
```text
library(Rstat)

# 1. Probability Distribution
n <- 5
p <- 1/3
x <- 0:n

px <- dbinom(x, n, p); px

# 2. E(X) and Var(X)
disc.exp(x, px)

# 3. Plot
disc.exp(x, px, prt=FALSE, plot=TRUE)

# 4. Cumulative Distribution
disc.cdf(x, px)
```
{% endtab %}

{% tab title="Probability Distribution Plot" %}
![](../.gitbook/assets/image%20%28165%29.png)
{% endtab %}

{% tab title="Cumulative Distribution Plot" %}
![](../.gitbook/assets/image%20%28160%29.png)

* $$P(X≤1)=0.4609$$
* $$P(X≤2)=0.79$$
{% endtab %}
{% endtabs %}

## 4. The Binomial Distribution in R

### 4-1. Sampling

$$x$$ : $$n=20$$ trials, tossing coins, probability of sucess = 0.5

{% tabs %}
{% tab title="R Source" %}
```text
sample(c("H", "T"), size=20, replace=TRUE, prob=c(0.5, 0.5))
```
{% endtab %}

{% tab title="1. Sampling" %}
```text
> sample(c("H", "T"), size=20, replace=TRUE, prob=c(0.5, 0.5))
 [1] "T" "H" "H" "T" "H" "T" "H" "H" "T" "T" "H" "T" "T" "T" "H" "H" "H" "T" "T" "T"
> sample(c("H", "T"), size=20, replace=TRUE, prob=c(0.5, 0.5))
 [1] "T" "T" "H" "T" "T" "H" "H" "H" "T" "T" "T" "T" "H" "H" "T" "T" "H" "H" "T" "T"
> sample(c("H", "T"), size=20, replace=TRUE, prob=c(0.5, 0.5))
 [1] "H" "H" "H" "T" "T" "H" "H" "H" "T" "H" "T" "T" "H" "T" "T" "T" "T" "T" "T" "H"
> sample(c("H", "T"), size=20, replace=TRUE, prob=c(0.5, 0.5))
 [1] "H" "T" "T" "H" "T" "T" "T" "H" "H" "T" "T" "T" "H" "T" "H" "T" "H" "H" "H" "H"
```
{% endtab %}
{% endtabs %}

### 4-2. Plotting

$$p = 0.5$$ , $$n=20 $$ 

#### 1\) Probability Distribution Function

`dbinom(x, size = , prob = )` 함수 이용.

{% tabs %}
{% tab title="R Source" %}
```text
y  <- dbinom(0:20, size=20, prob=0.5)
plot(0:20, y, type='h', lwd=5, col="grey", 
     ylab="Probability", xlab="확률변수 X", 
     main = c("X ~ B(20, 0.5)"))
     
y  <- dbinom(0:50, size=50, prob=0.5)
plot(0:50, y, type='h', lwd=5, col="grey", 
     ylab="Probability", xlab="확률변수 X", 
     main = c("X ~ B(50, 0.5)"))

y  <- dbinom(0:100, size=100, prob=0.5)
plot(0:100, y, type='h', lwd=5, col="grey", 
     ylab="Probability", xlab="확률변수 X", 
     main = c("X ~ B(100, 0.5)"))
```
{% endtab %}

{% tab title="Plotting" %}
![](../.gitbook/assets/image%20%2838%29.png)

![](../.gitbook/assets/image%20%28111%29.png)

![](../.gitbook/assets/image%20%2868%29.png)
{% endtab %}
{% endtabs %}

#### 2\) Cumulative Distribution Function

{% tabs %}
{% tab title="R Source" %}
```text
plot(pbinom(0:20, size=20, prob=0.5), type='h')
plot(pbinom(0:50, size=50, prob=0.5), type='h')
plot(pbinom(0:100, size=100, prob=0.5), type='h')
```
{% endtab %}

{% tab title="Cdf" %}
![](../.gitbook/assets/image%20%28215%29.png)

![](../.gitbook/assets/image%20%2819%29.png)

![](../.gitbook/assets/image%20%28238%29.png)
{% endtab %}
{% endtabs %}

### 4-3. Calculation of the Probability

#### 1\) $$P(x=12)$$ 

 `dbinom(x, size, prob)`

{% tabs %}
{% tab title="R Source" %}
```text
x <- 12
dbinom(x, size=20, prob=0.5)
```
{% endtab %}

{% tab title="P\(x=12\)" %}
```text
> dbinom(x, size=20, prob=0.5)
[1] 0.1201344
```
{% endtab %}
{% endtabs %}

#### 2\) $$p(X <= 12)$$ 

`pbinom(x, size, prob, lower.tail=TRUE)`

{% tabs %}
{% tab title="R Source" %}
```text
x <- 12
pbinom(x, size=20, prob=0.5, lower.tail = TRUE)

# or

sum(dbinom(0:x, size=20, prob=0.5))
```
{% endtab %}

{% tab title="P\(x<=12\)" %}
```text
> pbinom(x, size=20, prob=0.5, lower.tail = TRUE)
[1] 0.868412

> sum(dbinom(0:x, size=20, prob=0.5))
[1] 0.868412
```
{% endtab %}
{% endtabs %}

#### 3\) $$p(x>12)$$ 

`pbinom(x, size, prob, lower.tail=FALSE)`

{% tabs %}
{% tab title="R Source" %}
```text
pbinom(12, size=20, prob=0.5, lower.tail = FALSE)

# or

1 - pbinom(12, size=20, prob=0.5, lower.tail = TRUE)
```
{% endtab %}

{% tab title="P\(x>12\)" %}
```text
> pbinom(12, size=20, prob=0.5, lower.tail = FALSE)
[1] 0.131588
> 
> # or
> 
> 1 - pbinom(12, size=20, prob=0.5, lower.tail = TRUE)
[1] 0.131588
```
{% endtab %}
{% endtabs %}

### 4-4. Generating the Random Numbers of Binomial

`rbinom(n, size, prob)`

{% tabs %}
{% tab title="R Source" %}
```text
rbinom(12, size=20, prob=0.5)
```
{% endtab %}

{% tab title="Random Numbers" %}
```text
> rbinom(12, size=20, prob=0.5)
 [1]  8 10  9  7 11  8 11  9 10 12 11  7
> rbinom(12, size=20, prob=0.5)
 [1] 11 11  8  7 12  9  6 11  9  8 10  7
> rbinom(12, size=20, prob=0.5)
 [1] 10 10  9  9 13 12 10  9 10  7 12  9
> rbinom(12, size=20, prob=0.5)
 [1]  9 10 10 11  6  9 14 13 12  7 11  7
```
{% endtab %}
{% endtabs %}

\*\*\*\*

**EXAMPLE 12.**  성공확률이 각각 0.2, 0.5, 0.8 \( $$p=0.2, 0.5, 0.8$$ \)인 무한모집단에서 10개의 표본\( $$n=10$$\)을 취하였을 때 나타나는 성공횟수의 확률분포 그래프를 작성하고, 기대값과 분산을 구하여 비교하라.

**\[ Solution \]**

{% tabs %}
{% tab title="R Source" %}
```text
library(Rstat)

# 1. Number of Trial(n), Success Ratio(p), Number of Success(x)
n <- 10
p <- c(0.2, 0.5, 0.8)
x <- 0:n

# Make empty list
fx1 <- list()

# Compute the Probability Distribution of each p
for (i in 1:3) fx1[[i]] <- dbinom(x, n, p[i])
# Summation of Each fx1
sapply(fx1, sum)

# E(X), Var(X), and Plot using disc.mexp()
mt1 <- paste0("B(10,", p, ")")   # Title of the plot
disc.mexp(x, fx1, mt=mt1)        # E(X), Var(X) and Plot
```
{% endtab %}

{% tab title="E\(X\) and Var\(X\)" %}
```text
> disc.mexp(x, fx1, mt=mt1)        # E(X), Var(X)
## E(X) = 2         V(X) = 5.6 - 2² = 1.6          D(X) = √(1.6) = 1.265 
## E(X) = 5         V(X) = 27.5 - 5² = 2.5         D(X) = √(2.5) = 1.581 
## E(X) = 8         V(X) = 65.6 - 8² = 1.6         D(X) = √(1.6) = 1.265 
```
{% endtab %}

{% tab title="Plots" %}
![](../.gitbook/assets/image%20%2874%29.png)
{% endtab %}
{% endtabs %}

